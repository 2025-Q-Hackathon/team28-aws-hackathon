import json
import boto3
import re
from typing import Dict, List, Any

bedrock = boto3.client('bedrock-runtime')

def lambda_handler(event, context):
    """ë‹µë³€ ìƒì„± Lambda í•¨ìˆ˜"""
    try:
        # CORS í—¤ë”
        headers = {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Methods': 'POST, OPTIONS',
            'Access-Control-Allow-Headers': 'Content-Type'
        }
        
        # OPTIONS ìš”ì²­ ì²˜ë¦¬
        if event.get('httpMethod') == 'OPTIONS':
            return {
                'statusCode': 200,
                'headers': headers,
                'body': ''
            }
        
        # ìš”ì²­ ë³¸ë¬¸ íŒŒì‹±
        body = json.loads(event.get('body', '{}'))
        context_text = body.get('context', '')
        situation = body.get('situation', '')
        user_style = body.get('user_style', {})
        partner_info = body.get('partner_info', {})
        
        # ë‹µë³€ ìƒì„±
        responses = generate_responses(context_text, situation, user_style, partner_info)
        
        return {
            'statusCode': 200,
            'headers': headers,
            'body': json.dumps({'responses': responses})
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': headers,
            'body': json.dumps({'error': str(e)})
        }

def generate_responses(context: str, situation: str, user_style: Dict, partner_info: Dict) -> List[Dict]:
    """AI ë‹µë³€ 3ì•ˆ ìƒì„±"""
    
    # íŒŒíŠ¸ë„ˆ ì •ë³´ ë¬¸ìì—´ ìƒì„±
    partner_context = ""
    if partner_info.get('name'):
        partner_context += f"ìƒëŒ€ë°©: {partner_info['name']}\n"
    if partner_info.get('relationship'):
        partner_context += f"ê´€ê³„: {partner_info['relationship']}\n"
    if partner_info.get('personality'):
        partner_context += f"ì„±ê²©: {partner_info['personality']}\n"
    
    prompt = f"""
ë‹¹ì‹ ì€ ì—°ì•  ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìƒí™©ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ 3ê°€ì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

{partner_context}
ëŒ€í™” ë§¥ë½: {context}
í˜„ì¬ ìƒí™©: {situation}

ì‚¬ìš©ì ë§íˆ¬ íŠ¹ì„±:
- ì¡´ëŒ“ë§ ë¹„ìœ¨: {user_style.get('formal_ratio', 0.3):.1%}
- ì´ëª¨í‹°ì½˜ ì‚¬ìš©: {user_style.get('emoji_ratio', 0.2):.1f}ê°œ/ë©”ì‹œì§€
- í‰ê·  ë©”ì‹œì§€ ê¸¸ì´: {user_style.get('avg_length', 20):.0f}ì

3ê°€ì§€ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
1. ì•ˆì „í˜•: ë¬´ë‚œí•˜ê³  ì•ˆì „í•œ ë‹µë³€
2. í‘œì¤€í˜•: ì ë‹¹íˆ ê´€ì‹¬ì„ ë³´ì´ëŠ” ë‹µë³€  
3. ëŒ€ë‹´í˜•: ì ê·¹ì ì´ê³  í˜¸ê°ì„ ë“œëŸ¬ë‚´ëŠ” ë‹µë³€

ê° ë‹µë³€ë§ˆë‹¤ ì™œ ì´ ë‹µë³€ì´ ì í•©í•œì§€, ì–´ë–¤ ë¦¬ìŠ¤í¬ê°€ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "responses": [
    {{
      "type": "ì•ˆì „í˜•",
      "message": "ë‹µë³€ ë‚´ìš©",
      "explanation": "ì´ ë‹µë³€ì´ ì í•©í•œ ì´ìœ ",
      "risk_level": 1,
      "confidence": 0.9
    }}
  ]
}}
"""

    try:
        # AWS Bedrock í˜¸ì¶œ
        response = bedrock.invoke_model(
            modelId='anthropic.claude-3-sonnet-20240229-v1:0',
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 2000,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            })
        )
        
        response_body = json.loads(response['body'].read())
        ai_response = response_body['content'][0]['text']
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            parsed_response = json.loads(ai_response)
            return parsed_response.get('responses', [])
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            pass
            
    except Exception as e:
        print(f"Bedrock API error: {e}")
    
    # ê¸°ë³¸ ì‘ë‹µ (API ì‹¤íŒ¨ ì‹œ)
    return [
        {
            "type": "ì•ˆì „í˜•",
            "message": "ê·¸ë ‡êµ¬ë‚˜! ì¬ë°Œê² ë‹¤ ğŸ˜Š",
            "explanation": "ë¬´ë‚œí•˜ê³  ì•ˆì „í•œ ë°˜ì‘ìœ¼ë¡œ ë¶€ë‹´ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "risk_level": 1,
            "confidence": 0.9
        },
        {
            "type": "í‘œì¤€í˜•",
            "message": "ì˜¤ ì¢‹ì€ë°? ë‚˜ë„ ê´€ì‹¬ìˆì–´!",
            "explanation": "ì ë‹¹í•œ ê´€ì‹¬ì„ í‘œí˜„í•˜ë©° ëŒ€í™”ë¥¼ ì´ì–´ê°‘ë‹ˆë‹¤.",
            "risk_level": 2,
            "confidence": 0.8
        },
        {
            "type": "ëŒ€ë‹´í˜•",
            "message": "ì™„ì „ ì¢‹ì•„! ê°™ì´ í•´ë³¼ê¹Œ? ğŸ˜",
            "explanation": "ì ê·¹ì ì¸ í˜¸ê°ì„ ë“œëŸ¬ë‚´ë©° í•¨ê»˜í•˜ê³  ì‹¶ë‹¤ëŠ” ì˜ì‚¬ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤.",
            "risk_level": 4,
            "confidence": 0.7
        }
    ]
      "risk_level": "ë‚®ìŒ/ë³´í†µ/ë†’ìŒ",
      "confidence": 85
    }}
  ]
}}
"""

    try:
        response = bedrock.invoke_model(
            modelId='anthropic.claude-3-sonnet-20240229-v1:0',
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 1000,
                "messages": [{"role": "user", "content": prompt}]
            })
        )
        
        result = json.loads(response['body'].read())
        content = result['content'][0]['text']
        
        # JSON íŒŒì‹±
        responses_data = json.loads(content)
        return responses_data['responses']
        
    except Exception as e:
        # í´ë°± ì‘ë‹µ
        return [
            {
                "type": "ì•ˆì „í˜•",
                "message": "ì•„ ê·¸ë ‡êµ¬ë‚˜! ë‚˜ë„ ê·¸ëŸ° ìƒê° í•´ë³¸ ì  ìˆì–´",
                "explanation": "ë¬´ë‚œí•˜ê³  ê³µê°í•˜ëŠ” ë‹µë³€ìœ¼ë¡œ ì•ˆì „í•©ë‹ˆë‹¤",
                "risk_level": "ë‚®ìŒ",
                "confidence": 75
            },
            {
                "type": "í‘œì¤€í˜•", 
                "message": "ì˜¤ ì¬ë°Œë„¤! ë‚˜ë„ ê·¸ëŸ° ê±° ì¢‹ì•„í•´ ã…ã…",
                "explanation": "ê´€ì‹¬ì„ ë³´ì´ë©´ì„œë„ ë¶€ë‹´ìŠ¤ëŸ½ì§€ ì•Šì€ ë‹µë³€",
                "risk_level": "ë³´í†µ",
                "confidence": 80
            },
            {
                "type": "ëŒ€ë‹´í˜•",
                "message": "ìš°ì™€ ì™„ì „ ë‚´ ìŠ¤íƒ€ì¼ì´ì•¼! ì–¸ì œ ê°™ì´ í•´ë³¼ê¹Œ? ğŸ˜Š",
                "explanation": "ì ê·¹ì ì¸ í˜¸ê° í‘œí˜„ìœ¼ë¡œ ê´€ê³„ ë°œì „ ê°€ëŠ¥ì„± ë†’ìŒ",
                "risk_level": "ë†’ìŒ", 
                "confidence": 70
            }
        ]

def lambda_handler(event, context):
    try:
        body = json.loads(event['body']) if isinstance(event.get('body'), str) else event.get('body', {})
        
        chat_history = body.get('chat_history', [])
        situation = body.get('situation', 'ì¼ë°˜ ëŒ€í™”')
        recent_context = body.get('recent_context', '')
        
        # ì‚¬ìš©ì ë§íˆ¬ ë¶„ì„
        user_messages = [msg for msg in chat_history if msg.get('sender') == 'user']
        user_texts = [msg['text'] for msg in user_messages]
        user_style = analyze_chat_style(user_texts)
        
        # AI ë‹µë³€ ìƒì„±
        responses = generate_responses(recent_context, situation, user_style)
        
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'user_style': user_style,
                'responses': responses,
                'analysis_complete': True
            }, ensure_ascii=False)
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'error': str(e),
                'message': 'Internal server error'
            })
        }
